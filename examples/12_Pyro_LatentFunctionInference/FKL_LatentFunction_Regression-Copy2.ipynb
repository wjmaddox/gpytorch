{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import time\n",
    "\n",
    "import pyro\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we how to train a functional kernel learning model, training on a simple function. We'll be modeling the function\n",
    "\n",
    "\\begin{align*}\n",
    "  y &= \\sin(2\\pi x) + \\epsilon \\\\\n",
    "  \\epsilon &\\sim \\mathcal{N}(0, 0.2)\n",
    "\\end{align*}\n",
    "\n",
    "with 11 training examples, and testing on 51 test examples.\n",
    "\n",
    "For more mathematical detail, please see the paper Functional Distributions over Kernels (NeurIPS 2019).\n",
    "\n",
    "**Note:** this notebook is not necessarily intended to teach the mathematical background of Gaussian processes, but rather how to train a simple one and make predictions in GPyTorch. For a mathematical treatment, Chapter 2 of Gaussian Processes for Machine Learning provides a very thorough introduction to GP regression (this entire text is highly recommended): http://www.gaussianprocess.org/gpml/chapters/RW2.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the GPyTorch Model with Spectral GP kernel\n",
    "Using the same framework as standard GPyTorch models, we merely drop-in the spectral GP kernel as the covar module\n",
    "\n",
    "The `initialize_from_data` method does some pre-training on the latent model using the log-periodogram of data as training targets.\n",
    "\n",
    "For specifics on the components of GPyTorch models we refer to the [GPyTorch Documentation](https://gpytorch.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, **kwargs):\n",
    "        super(SpectralModel, self).__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.SpectralGPKernel(**kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training data and Build GP Model\n",
    "Generate points in [0, 5] and a sine wave to serve as the response, then split into training and test data.\n",
    "\n",
    "Pass this data into the GP model from above along with a likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 200\n",
    "split = 150\n",
    "full_x = torch.linspace(0, 5, nx).cuda()\n",
    "full_y = torch.sin(2 * full_x)\n",
    "\n",
    "train_x = full_x[:split]\n",
    "train_y = full_y[:split]\n",
    "\n",
    "test_x = full_x[(split - nx):]\n",
    "test_y = full_y[(split - nx):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define latent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FKL_GPModel(gpytorch.likelihoods.GaussianLikelihood):\n",
    "    def __init__(self, train_x, train_y, data_likelihood, **kwargs):\n",
    "        super(FKL_GPModel, self).__init__()\n",
    "        \n",
    "        self._max_plate_nesting = 1\n",
    "        self.data_likelihood = data_likelihood\n",
    "        self.data_model = SpectralModel(train_x, train_y, self.data_likelihood, \n",
    "                                        **kwargs)\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "              \n",
    "    def forward(self, target, input, *params, **kwargs):\n",
    "        latent_gp = input.mean\n",
    "        \n",
    "        self.data_model.covar_module.set_latent_params(latent_gp)\n",
    "        \n",
    "        self.data_model.train()\n",
    "        \n",
    "        if not self.training:\n",
    "            self.data_model.eval()\n",
    "            dist = self.data_model(*params, **kwargs)\n",
    "        else:\n",
    "            dist = self.data_likelihood(self.data_model(self.train_x))\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                print('forwards into dist: ', dist.log_prob(self.train_y))\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (quadrature): GaussHermiteQuadrature1D()\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (noise_prior): SmoothedBoxPrior()\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#omega = torch.arange(1e-4, 1., 0.01)\n",
    "\n",
    "data_lh = gpytorch.likelihoods.GaussianLikelihood(noise_prior=gpytorch.priors.SmoothedBoxPrior(1e-8, 1e-4)).cuda()\n",
    "data_gp = FKL_GPModel(train_x, train_y, data_lh, train_inputs = train_x, register_latent_params=False).cuda()\n",
    "data_gp.train()\n",
    "data_lh.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = data_gp.data_model.covar_module.omega.data.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.means import QuadraticMean\n",
    "from gpytorch.priors import NormalPrior\n",
    "from gpytorch.constraints import LessThan\n",
    "from gpytorch.kernels import ScaleKernel, MaternKernel, GridKernel\n",
    "from gpytorch.models import PyroVariationalGP\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, VariationalStrategy\n",
    "\n",
    "# we construct a Scale(Matern 3/2) kernel with a quadratic mean by default\n",
    "class LatentGPModel(gpytorch.models.AbstractVariationalGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, mean_module, covar_module):\n",
    "        # Define all the variational stuff\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            num_inducing_points=int(train_x.numel())\n",
    "        )\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self, train_x, variational_distribution\n",
    "        )\n",
    "\n",
    "        super(LatentGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = mean_module\n",
    "        self.covar_module = covar_module\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        covar = self.covar_module(x)\n",
    "        return MultivariateNormal(mean, covar)\n",
    "\n",
    "# construct by default a LogRBF prior on the latent spectral GP\n",
    "latent_mean = QuadraticMean()#.to(device)\n",
    "latent_mean.register_prior(\n",
    "    \"bias_prior\",\n",
    "    prior=NormalPrior(torch.zeros(1), 100.0 * torch.ones(1), transform=None),\n",
    "    param_or_closure=\"bias\"\n",
    ")\n",
    "latent_mean.register_constraint(\"quadratic_weights\", constraint=LessThan(upper_bound=0.0))\n",
    "latent_mean.register_prior(\n",
    "    \"quadratic_weights_prior\",\n",
    "    prior=NormalPrior(\n",
    "        torch.zeros(1),\n",
    "        100.0 * torch.ones(1),\n",
    "        transform=torch.nn.functional.softplus,\n",
    "    ),\n",
    "    param_or_closure=\"quadratic_weights\"\n",
    ")\n",
    "\n",
    "latent_covar = ScaleKernel(\n",
    "    MaternKernel(nu=1.5, lengthscale_prior=NormalPrior(torch.zeros(1), torch.ones(1), transform=torch.exp)),\n",
    "    outputscale_prior=NormalPrior(torch.zeros(1), torch.ones(1), transform=torch.exp),\n",
    ")\n",
    "# latent_covar = GridKernel(latent_covar, grid=self.omega.unsqueeze(-1))\n",
    "\n",
    "latent_model = LatentGPModel(\n",
    "    omega, None, data_gp, mean_module=latent_mean, covar_module=latent_covar\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gp.train();\n",
    "latent_model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (150) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9b3844953ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlatent_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprior_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprior_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/likelihood.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input, *params, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# Conditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;31m# Marginal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             elif any([\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/likelihood.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input, *params, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Conditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Marginal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/gaussian_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_samples, *params, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbase_distributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shaped_noise_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_distributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmarginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_dist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     31\u001b[0m         values = [v if torch.is_tensor(v) else torch.tensor(v, **options)\n\u001b[1;32m     32\u001b[0m                   for v in values]\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (150) at non-singleton dimension 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/wesley/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m(52)\u001b[0;36mbroadcast_tensors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     50 \u001b[0;31m                [0, 1, 2]])\n",
      "\u001b[0m\u001b[0;32m     51 \u001b[0;31m    \"\"\"\n",
      "\u001b[0m\u001b[0;32m---> 52 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     53 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     54 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/anaconda3/lib/python3.7/site-packages/torch/distributions/utils.py\u001b[0m(33)\u001b[0;36mbroadcast_all\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     31 \u001b[0;31m        values = [v if torch.is_tensor(v) else torch.tensor(v, **options)\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m                  for v in values]\n",
      "\u001b[0m\u001b[0;32m---> 33 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m(44)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     42 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 44 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     46 \u001b[0;31m            \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/gaussian_likelihood.py\u001b[0m(43)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     41 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbase_distributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     42 \u001b[0;31m        \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shaped_noise_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 43 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mbase_distributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     44 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     45 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mmarginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_dist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> function_samples\n",
      "tensor([ 0.9143,  0.8088,  0.4365,  0.1067,  0.1153, -0.1164, -0.3102,  0.1845,\n",
      "         0.7008,  1.3262,  1.3993,  1.0417,  0.8893,  0.7571,  0.7995,  0.0605,\n",
      "        -0.1652,  0.2223,  0.7226,  0.6930,  0.4755,  0.8699,  1.2511,  1.4827,\n",
      "         1.0610,  0.5035,  0.6980,  0.7145,  1.3426,  1.1889,  0.7820,  0.4238,\n",
      "         0.6127,  0.8161,  0.8802,  0.8996,  0.9877,  1.7074,  1.9940,  2.3819,\n",
      "         1.9741,  1.7561,  2.0416,  2.4312,  1.9133,  2.0925,  2.0627,  2.3866,\n",
      "         2.3666,  1.7558], device='cuda:0')\n",
      "ipdb> function_samples.shape\n",
      "torch.Size([50])\n",
      "ipdb> noise.sqrt()\n",
      "tensor([0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326,\n",
      "        0.8326, 0.8326, 0.8326, 0.8326, 0.8326, 0.8326], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward>)\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/Documents/Code/wjm_gpytorch/gpytorch/module.py\u001b[0m(22)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     20 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 22 \u001b[0;31m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     23 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     24 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/likelihood.py\u001b[0m(120)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    118 \u001b[0;31m        \u001b[0;31m# Conditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 120 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m        \u001b[0;31m# Marginal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m        \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/wesley/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/likelihood.py\u001b[0m(209)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    207 \u001b[0;31m            \u001b[0;31m# Conditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    208 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 209 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    210 \u001b[0;31m            \u001b[0;31m# Marginal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    211 \u001b[0;31m            elif any([\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-18-9b3844953ee7>\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0mlatent_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0mprior_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mprior_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> latent_sample\n",
      "tensor([ 0.9143,  0.8088,  0.4365,  0.1067,  0.1153, -0.1164, -0.3102,  0.1845,\n",
      "         0.7008,  1.3262,  1.3993,  1.0417,  0.8893,  0.7571,  0.7995,  0.0605,\n",
      "        -0.1652,  0.2223,  0.7226,  0.6930,  0.4755,  0.8699,  1.2511,  1.4827,\n",
      "         1.0610,  0.5035,  0.6980,  0.7145,  1.3426,  1.1889,  0.7820,  0.4238,\n",
      "         0.6127,  0.8161,  0.8802,  0.8996,  0.9877,  1.7074,  1.9940,  2.3819,\n",
      "         1.9741,  1.7561,  2.0416,  2.4312,  1.9133,  2.0925,  2.0627,  2.3866,\n",
      "         2.3666,  1.7558], device='cuda:0')\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "cols = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "for sample_num in range(5):\n",
    "    latent_sample = latent_model(omega).sample()\n",
    "    \n",
    "    prior_dist = data_gp(latent_sample, train_x)\n",
    "    prior_preds = prior_dist.sample(torch.Size((3,)))\n",
    "    \n",
    "    plt.plot(train_x.cpu(), prior_preds.data.cpu().t().numpy(), color = cols[sample_num], alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_x, train_y), \n",
    "                                           batch_size = 150, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesley/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (150) must match the size of tensor b (50) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-397013cbbbd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# with combine_terms=False, we get the terms of the ELBO separated so we can print them individually if we'd like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# loss = -mll(output, y_batch) would also work.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mlog_lik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_lik\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d [%d/%d] - Loss: %.3f [%.3f, %.3f, %.3f]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_lik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/mlls/variational_elbo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, variational_dist_f, target, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariational_dist_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         log_likelihood = self.likelihood.expected_log_prob(target, variational_dist_f, **kwargs).div(\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mnum_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         )\n",
      "\u001b[0;32m~/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/gaussian_likelihood.py\u001b[0m in \u001b[0;36mexpected_log_prob\u001b[0;34m(self, target, input, *params, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (150) must match the size of tensor b (50) at non-singleton dimension 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/wesley/Documents/Code/wjm_gpytorch/gpytorch/likelihoods/gaussian_likelihood.py\u001b[0m(84)\u001b[0;36mexpected_log_prob\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     82 \u001b[0;31m        \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     83 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 84 \u001b[0;31m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     86 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> ll\n",
      "\u001b[1;32m     80 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mexpected_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     81 \u001b[0m        \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     82 \u001b[0m        \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     83 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 84 \u001b[0;31m        \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     85 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     86 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> target\n",
      "tensor([-0.9981,  0.9144,  0.5470,  0.2953,  0.4354, -0.9713, -0.3462, -0.8709,\n",
      "         0.1484,  0.9653,  0.6844, -0.2014, -0.8299, -0.5266,  0.0260,  0.1997,\n",
      "        -0.8817,  0.4151, -0.7698, -0.1741, -0.4386,  0.9151,  0.2486, -0.9426,\n",
      "         0.0502, -0.7553, -0.9960,  0.4602, -0.9348, -0.5027,  0.5235,  0.3217,\n",
      "         0.2469,  0.0986,  0.8929, -0.5686, -0.9999,  0.8578,  0.1758, -0.9657,\n",
      "        -0.9938, -0.2233,  0.2970,  0.9253,  0.9980,  0.5671,  0.7541,  0.0485,\n",
      "         0.8152, -0.3672, -0.7368,  0.6282, -0.4587, -0.9582, -0.8569,  0.6078,\n",
      "         0.7529, -0.0018,  0.7850,  0.8019,  0.9336,  0.9718,  0.8937,  0.4801,\n",
      "        -0.0744, -0.9158,  0.7380,  0.8162, -0.2720,  0.9962, -0.1021,  0.6064,\n",
      "         0.2251, -0.9869,  0.9936,  0.1262, -0.3200, -0.0242, -0.8172,  0.3896,\n",
      "         0.7202,  0.5043,  0.3913,  0.9342, -0.9515,  0.9993,  0.3445,  0.0762,\n",
      "        -0.5455, -0.0520,  0.5657,  0.9905, -0.9043,  0.4816, -0.6857, -0.1244,\n",
      "        -0.8451, -0.8009, -0.6268,  0.9772, -0.6483, -0.9246,  0.8309,  0.8442,\n",
      "         0.5884,  0.7709,  0.8432,  0.3689, -0.9992,  0.5250, -0.2503,  0.2737,\n",
      "         0.9432,  0.0000,  0.8700, -0.4135,  0.1502, -0.9776, -0.7214, -0.4832,\n",
      "         0.6455, -0.7872, -0.3929,  0.1003,  0.9999, -0.2987,  0.9866,  0.9587,\n",
      "         0.6665,  0.6469,  0.6831, -0.6092, -0.9820,  0.1979, -0.7019, -0.6652,\n",
      "        -0.8945,  0.9509,  0.8692,  0.9824,  0.9051,  0.7861,  0.4370, -0.1519,\n",
      "         0.3429,  0.7031, -0.9903,  0.8826,  0.7189, -0.5869], device='cuda:0')\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "latent_model.train()\n",
    "data_gp.train()\n",
    "\n",
    "# We'll do 6 epochs of training in this tutorial\n",
    "num_epochs = 40\n",
    "\n",
    "# We use SGD here, rather than Adam. Emperically, we find that SGD is better for variational regression\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': latent_model.parameters()},\n",
    "    {'params': data_gp.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 5], gamma=0.1)\n",
    "\n",
    "# Our loss object. We're using the VariationalELBO, which essentially just computes the ELBO\n",
    "mll = gpytorch.mlls.VariationalELBO(data_gp, latent_model, num_data=train_y.size(0), combine_terms=False)\n",
    "\n",
    "# We use more CG iterations here because the preconditioner introduced in the NeurIPS paper seems to be less\n",
    "# effective for VI.\n",
    "with gpytorch.settings.max_cg_iterations(45):\n",
    "    for i in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        # Within each iteration, we will go over each minibatch of data\n",
    "        for minibatch_i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            start_time = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            output = latent_model(omega)\n",
    "            # with combine_terms=False, we get the terms of the ELBO separated so we can print them individually if we'd like.\n",
    "            # loss = -mll(output, y_batch) would also work.\n",
    "            log_lik, kl_div, log_prior = mll(output, y_batch)\n",
    "            loss = -(log_lik - kl_div + log_prior)\n",
    "            print('Epoch %d [%d/%d] - Loss: %.3f [%.3f, %.3f, %.3f]' % (i + 1, minibatch_i, len(train_loader), loss.item(), log_lik.item(), kl_div.item(), log_prior.item()))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic lr for most of parameters: 0.01\n",
      "forwards into dist:  tensor(-271.0613, device='cuda:0')\n",
      "forwards into dist:  tensor(-283.2576, device='cuda:0')\n",
      "tensor(-44.7022, device='cuda:0', grad_fn=<SumBackward0>) tensor(7.8205, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-297.0042, device='cuda:0')\n",
      "tensor(-42.5959, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.3975, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-290.5873, device='cuda:0')\n",
      "tensor(-57.0369, device='cuda:0', grad_fn=<SumBackward0>) tensor(9.2815, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-276.0399, device='cuda:0')\n",
      "tensor(-68.8978, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.3217, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-283.0795, device='cuda:0')\n",
      "tensor(-65.2813, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.9567, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Iter 5/15 - Loss: 1.42e+04   lengthscale: 0.607\n",
      "forwards into dist:  tensor(-288.1610, device='cuda:0')\n",
      "tensor(-60.0140, device='cuda:0', grad_fn=<SumBackward0>) tensor(10.2874, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-278.6920, device='cuda:0')\n",
      "tensor(-52.9591, device='cuda:0', grad_fn=<SumBackward0>) tensor(7.9796, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-287.0645, device='cuda:0')\n",
      "tensor(-55.3452, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.5480, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-278.9220, device='cuda:0')\n",
      "tensor(-57.9237, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.9001, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-276.0008, device='cuda:0')\n",
      "tensor(-55.0786, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.2128, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Iter 10/15 - Loss: 1.4e+04   lengthscale: 0.449\n",
      "forwards into dist:  tensor(-264.0885, device='cuda:0')\n",
      "tensor(-52.9990, device='cuda:0', grad_fn=<SumBackward0>) tensor(7.4462, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-288.0634, device='cuda:0')\n",
      "tensor(-47.2155, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.6067, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-273.8037, device='cuda:0')\n",
      "tensor(-58.6919, device='cuda:0', grad_fn=<SumBackward0>) tensor(9.2780, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-274.9730, device='cuda:0')\n",
      "tensor(-55.7021, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.2902, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "forwards into dist:  tensor(-272.7043, device='cuda:0')\n",
      "tensor(-54.1651, device='cuda:0', grad_fn=<SumBackward0>) tensor(8.3808, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "Iter 15/15 - Loss: 1.39e+04   lengthscale: 0.351\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "from pyro import optim\n",
    "\n",
    "base_lr = 1e-2\n",
    "iter_print = 5\n",
    "\n",
    "print('Basic lr for most of parameters: {}'.format(base_lr))\n",
    "\n",
    "# set learning rates for different hyperparameters\n",
    "def per_param_callable(module_name, param_name):\n",
    "    if param_name == 'covar_module.base_kernel.raw_lengthscale':\n",
    "        return {\"lr\": 0.1}\n",
    "    elif param_name == 'variational_strategy.variational_distribution.variational_mean':\n",
    "        return {\"lr\": base_lr}\n",
    "    else:\n",
    "        return {\"lr\": base_lr}\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = optim.Adam(per_param_callable)\n",
    "\n",
    "pyro.clear_param_store() # clean run\n",
    "\n",
    "losses, rbf, means = [], [], []\n",
    "\n",
    "means.append(latent_model.variational_strategy.variational_distribution.\\\n",
    "             variational_mean.detach().cpu().numpy()) #save initial mean\n",
    "\n",
    "#def train(num_iter=15):\n",
    "num_iter = 15\n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=1, vectorize_particles=True)\n",
    "svi = pyro.infer.SVI(latent_model.model, latent_model.guide, optimizer, elbo)\n",
    "latent_model.train()\n",
    "\n",
    "for i in range(num_iter):\n",
    "    latent_model.zero_grad()\n",
    "    loss = svi.step(omega, train_y)\n",
    "    print(latent_model(omega).log_prob(data_gp.data_model.covar_module.latent_params).sum(), \n",
    "         data_gp.data_model.covar_module.latent_params.norm())\n",
    "    losses.append(loss)\n",
    "    rbf.append(latent_model.covar_module.base_kernel.lengthscale.item())\n",
    "    if not (i + 1) % iter_print:\n",
    "        print('Iter {}/{} - Loss: {:.3}   lengthscale: {:.3}'.format(\n",
    "            i + 1, num_iter, loss,\n",
    "            latent_model.covar_module.base_kernel.lengthscale.item(),\n",
    "        ))\n",
    "        means.append(latent_model.variational_strategy.variational_distribution.\\\n",
    "                     variational_mean.detach().cpu().numpy())\n",
    "        \n",
    "#%time train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "guide() missing 2 required positional arguments: 'input' and 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fd756231b3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_plate_nesting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guess_max_plate_nesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_vectorized_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_vectorized_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         return self._get_trace(self._vectorized_num_particles(model),\n\u001b[1;32m    145\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorized_num_particles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                                *args, **kwargs)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[1;32m     49\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 50\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, *args, **kwargs)\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mguide_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     model_trace = poutine.trace(poutine.replay(model, trace=guide_trace),\n\u001b[1;32m     42\u001b[0m                                 graph_type=graph_type).get_trace(*args, **kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_particles_vectorized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: guide() missing 2 required positional arguments: 'input' and 'output'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/wesley/anaconda3/lib/python3.7/site-packages/pyro/infer/elbo.py\u001b[0m(132)\u001b[0;36mwrapped_fn\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    130 \u001b[0;31m        \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    131 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 132 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    133 \u001b[0;31m            \u001b[0;32mwith\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_particles_vectorized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "for obj in elbo._get_traces(latent_model.model, latent_model.guide):\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prot loss function and kernel length\n",
    "fig, (loss, kern) = plt.subplots(1,2,figsize=(12,2))\n",
    "loss.plot(losses)\n",
    "loss.set_xlabel(\"Epoch\")\n",
    "loss.set_ylabel(\"Loss\")\n",
    "kern.plot(rbf)\n",
    "kern.set_xlabel(\"Epoch\")\n",
    "kern.set_ylabel(\"Kernel scale parameter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.linspace(0, 15, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gp.eval()\n",
    "\n",
    "latent_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_dist = latent_model(omega)\n",
    "    \n",
    "samples = output_dist.sample(torch.Size((20,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(latent_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    if i is 0:\n",
    "        plt.plot(omega, sample.exp(), color = 'black', alpha = 0.3, label = 'S(w)')\n",
    "    else:\n",
    "        plt.plot(omega, sample.exp(), color = 'black', alpha = 0.3)\n",
    "\n",
    "plt.xlabel('omega')\n",
    "plt.ylabel('S(omega)')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(samples):\n",
    "    with gpytorch.settings.fast_pred_var():\n",
    "        pred_dist = data_gp(sample.data, test_x)\n",
    "    \n",
    "    pred_mean = pred_dist.mean.data.numpy()\n",
    "    lower, upper = pred_dist.confidence_region()\n",
    "    \n",
    "    if i is 0:\n",
    "        plt.plot(test_x, pred_mean, color = 'blue', label = 'Predictive Mean')\n",
    "    else:\n",
    "        plt.plot(test_x, pred_mean, color = 'blue')\n",
    "    \n",
    "    plt.fill_between(test_x.numpy(), lower.data.numpy(), upper.data.numpy(), alpha = 0.03, color = 'blue')\n",
    "    \n",
    "plt.plot(train_x, train_y, marker = 'x', color = 'black', label = 'Training Data')\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_output = data_gp.data_model.covar_module(torch.zeros(1), torch.linspace(0., 20., 100)).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.linspace(0., 20., 100), covar_output.view(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
